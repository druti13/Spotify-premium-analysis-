{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71fc3606-5ab1-49f0-9667-772c6e914f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " SPOTIFY DATA CLEANING & PREPARATION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" SPOTIFY DATA CLEANING & PREPARATION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b24380c-97c2-49ca-b247-a7ccb693c08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Loading Raw Data...\n",
      "âœ“ Loaded: 520 rows Ã— 20 columns\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD RAW DATA\n",
    "print(\"STEP 1: Loading Raw Data...\")\n",
    "\n",
    "df = pd.read_excel('data/raw/Spotify_data.xlsx')\n",
    "\n",
    "print(f\"âœ“ Loaded: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "\n",
    "# Keep original for comparison\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cec6bea-51cf-4bfc-8e31-61bca41bc96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: Standardizing Column Names\n",
      "======================================================================\n",
      "\n",
      "Original columns:\n",
      "['Age', 'Gender', 'spotify_usage_period', 'spotify_listening_device', 'spotify_subscription_plan', 'premium_sub_willingness', 'preffered_premium_plan', 'preferred_listening_content', 'fav_music_genre', 'music_time_slot', 'music_Influencial_mood', 'music_lis_frequency', 'music_expl_method', 'music_recc_rating', 'pod_lis_frequency', 'fav_pod_genre', 'preffered_pod_format', 'pod_host_preference', 'preffered_pod_duration', 'pod_variety_satisfaction']\n",
      "\n",
      "Cleaned columns:\n",
      "['age', 'gender', 'spotify_usage_period', 'spotify_listening_device', 'spotify_subscription_plan', 'premium_sub_willingness', 'preffered_premium_plan', 'preferred_listening_content', 'fav_music_genre', 'music_time_slot', 'music_influencial_mood', 'music_lis_frequency', 'music_expl_method', 'music_recc_rating', 'pod_lis_frequency', 'fav_pod_genre', 'preffered_pod_format', 'pod_host_preference', 'preffered_pod_duration', 'pod_variety_satisfaction']\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Handling Missing Values\n",
      "======================================================================\n",
      "\n",
      "Missing values found:\n",
      "preffered_premium_plan    208\n",
      "fav_pod_genre             148\n",
      "preffered_pod_format      140\n",
      "pod_host_preference       141\n",
      "preffered_pod_duration    129\n",
      "dtype: int64\n",
      "  â†’ Filled preffered_premium_plan with 'Unknown'\n",
      "  â†’ Filled fav_pod_genre with 'Unknown'\n",
      "  â†’ Filled preffered_pod_format with 'Unknown'\n",
      "  â†’ Filled pod_host_preference with 'Unknown'\n",
      "  â†’ Filled preffered_pod_duration with 'Unknown'\n"
     ]
    }
   ],
   "source": [
    "# 2. STANDARDIZE COLUMN NAMES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Standardizing Column Names\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nOriginal columns:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "# Clean column names: lowercase, remove spaces\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "print(\"\\nCleaned columns:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "# 3. HANDLE MISSING VALUES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Handling Missing Values\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"âœ“ No missing values found!\")\n",
    "else:\n",
    "    print(\"\\nMissing values found:\")\n",
    "    print(missing[missing > 0])\n",
    "    \n",
    "    # Fill strategy for text columns\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "            print(f\"  â†’ Filled {col} with 'Unknown'\")\n",
    "    \n",
    "    # Fill strategy for numeric columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "            print(f\"  â†’ Filled {col} with median value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73823dab-f60d-4f4b-9234-eebea1339407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: Removing Duplicates\n",
      "======================================================================\n",
      "âœ“ Removed 1 duplicate rows\n",
      "  Dataset size: 520 â†’ 519 rows\n"
     ]
    }
   ],
   "source": [
    "# 4. REMOVE DUPLICATES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: Removing Duplicates\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "after = len(df)\n",
    "removed = before - after\n",
    "\n",
    "if removed == 0:\n",
    "    print(\"âœ“ No duplicates found!\")\n",
    "else:\n",
    "    print(f\"âœ“ Removed {removed} duplicate rows\")\n",
    "    print(f\"  Dataset size: {before:,} â†’ {after:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e5cee73-1e70-4bb3-856f-1f5d482c080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ§¹ STEP 5: Cleaning Text Data\n",
      "======================================================================\n",
      "\n",
      "Cleaning text fields...\n",
      "  â†’ Standardized premium_sub_willingness\n",
      "  â†’ Standardized pod_variety_satisfaction\n",
      "âœ“ Text cleaning complete\n"
     ]
    }
   ],
   "source": [
    "# 5. CLEAN TEXT DATA\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ§¹ STEP 5: Cleaning Text Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nCleaning text fields...\")\n",
    "\n",
    "# Strip whitespace from all text columns\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "# Standardize Yes/No values\n",
    "yes_no_cols = ['premium_sub_willingness', 'pod_variety_satisfaction']\n",
    "for col in yes_no_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.title()  # Yes/No instead of yes/no or YES/NO\n",
    "        print(f\"  â†’ Standardized {col}\")\n",
    "\n",
    "print(\"âœ“ Text cleaning complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b90c032-2e26-4ea1-b84a-9333f3b56e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "âš™ï¸ STEP 6: Creating Derived Features\n",
      "======================================================================\n",
      "âœ“ Created: is_premium_willing\n",
      "âœ“ Created: is_premium_user\n",
      "âœ“ Created: is_podcast_listener\n",
      "âœ“ Created: engagement_score\n",
      "âœ“ Created: content_diversity\n",
      "âœ“ Created: high_satisfaction\n",
      "âœ“ Created: tenure_category\n",
      "\n",
      "âœ“ Total features now: 27\n"
     ]
    }
   ],
   "source": [
    "# 6. CREATE NEW FEATURES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš™ï¸ STEP 6: Creating Derived Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Binary: Is Premium Willing (1=Yes, 0=No)\n",
    "if 'premium_sub_willingness' in df.columns:\n",
    "    df['is_premium_willing'] = (df['premium_sub_willingness'].str.lower() == 'yes').astype(int)\n",
    "    print(\"âœ“ Created: is_premium_willing\")\n",
    "\n",
    "# 2. Binary: Is Premium User\n",
    "if 'spotify_subscription_plan' in df.columns:\n",
    "    df['is_premium_user'] = (df['spotify_subscription_plan'].str.lower() == 'premium').astype(int)\n",
    "    print(\"âœ“ Created: is_premium_user\")\n",
    "\n",
    "# 3. Binary: Is Podcast Listener\n",
    "if 'pod_lis_frequency' in df.columns:\n",
    "    df['is_podcast_listener'] = (~df['pod_lis_frequency'].str.lower().isin(['never', 'rarely'])).astype(int)\n",
    "    print(\"âœ“ Created: is_podcast_listener\")\n",
    "\n",
    "# 4. Engagement Score (0-10 based on listening frequency)\n",
    "if 'music_lis_frequency' in df.columns:\n",
    "    engagement_map = {\n",
    "        'daily': 10,\n",
    "        'several times a week': 8,\n",
    "        'weekly': 5,\n",
    "        'occasionally': 3,\n",
    "        'rarely': 1\n",
    "    }\n",
    "    # Apply mapping (case-insensitive)\n",
    "    df['engagement_score'] = df['music_lis_frequency'].str.lower().map(engagement_map)\n",
    "    df['engagement_score'] = df['engagement_score'].fillna(0)\n",
    "    print(\"âœ“ Created: engagement_score\")\n",
    "\n",
    "# 5. Content Diversity (Music only, Podcast only, or Both)\n",
    "if 'preferred_listening_content' in df.columns:\n",
    "    df['content_diversity'] = df['preferred_listening_content'].str.title()\n",
    "    print(\"âœ“ Created: content_diversity\")\n",
    "\n",
    "# 6. High Satisfaction Flag (recommendations rated 4+)\n",
    "if 'music_recc_rating' in df.columns:\n",
    "    df['high_satisfaction'] = (df['music_recc_rating'] >= 4).astype(int)\n",
    "    print(\"âœ“ Created: high_satisfaction\")\n",
    "\n",
    "# 7. User Tenure Category\n",
    "if 'spotify_usage_period' in df.columns:\n",
    "    def categorize_tenure(period):\n",
    "        period_lower = str(period).lower()\n",
    "        if 'less' in period_lower or '<' in period_lower:\n",
    "            return 'New User'\n",
    "        elif '6' in period_lower and '1' in period_lower:\n",
    "            return 'Growing User'\n",
    "        elif '1' in period_lower and '2' in period_lower:\n",
    "            return 'Established User'\n",
    "        elif 'more' in period_lower or '2+' in period_lower or '>' in period_lower:\n",
    "            return 'Loyal User'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    \n",
    "    df['tenure_category'] = df['spotify_usage_period'].apply(categorize_tenure)\n",
    "    print(\"âœ“ Created: tenure_category\")\n",
    "\n",
    "print(f\"\\nâœ“ Total features now: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4255b8e9-1f15-449f-b3a6-32ac5c129ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 7: Optimizing Data Types\n",
      "======================================================================\n",
      "Memory before: 0.67 MB\n",
      "Memory after:  0.66 MB\n"
     ]
    }
   ],
   "source": [
    "# 7. DATA TYPE OPTIMIZATION\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 7: Optimizing Data Types\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Memory before: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Convert numeric ratings to integer\n",
    "if 'music_recc_rating' in df.columns:\n",
    "    df['music_recc_rating'] = df['music_recc_rating'].astype('int8')\n",
    "\n",
    "print(f\"Memory after:  {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d512cf2f-0d3d-4cf1-b510-42fc1a09273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "âœ… STEP 8: Data Validation\n",
      "======================================================================\n",
      "\n",
      "Validation Checks:\n",
      "  âœ“ No missing values: True\n",
      "  âœ“ No duplicates: True\n",
      "  âœ“ Shape: 519 rows Ã— 27 columns\n",
      "\n",
      "  Target Variable Distribution:\n",
      "    Willing (1): 186 (35.8%)\n",
      "    Not Willing (0): 333 (64.2%)\n"
     ]
    }
   ],
   "source": [
    "# 8. VALIDATE CLEANED DATA\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… STEP 8: Data Validation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nValidation Checks:\")\n",
    "print(f\"  âœ“ No missing values: {df.isnull().sum().sum() == 0}\")\n",
    "print(f\"  âœ“ No duplicates: {df.duplicated().sum() == 0}\")\n",
    "print(f\"  âœ“ Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "\n",
    "# Check target distribution\n",
    "if 'is_premium_willing' in df.columns:\n",
    "    print(f\"\\n  Target Variable Distribution:\")\n",
    "    print(f\"    Willing (1): {df['is_premium_willing'].sum():,} ({df['is_premium_willing'].mean()*100:.1f}%)\")\n",
    "    print(f\"    Not Willing (0): {(~df['is_premium_willing'].astype(bool)).sum():,} ({(1-df['is_premium_willing'].mean())*100:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a39f788d-b9a8-4d33-bcf4-76fa5a59d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 9: Saving Cleaned Data\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\data\\cleaned'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m      6\u001b[39m output_path = \u001b[33m'\u001b[39m\u001b[33m../data/cleaned/spotify_cleaned.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ“ Cleaned data saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  â†’ File size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpd.read_csv(output_path).memory_usage(deep=\u001b[38;5;28;01mTrue\u001b[39;00m).sum()\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m1024\u001b[39m**\u001b[32m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MB\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '..\\data\\cleaned'"
     ]
    }
   ],
   "source": [
    "# 9. SAVE CLEANED DATA\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 9: Saving Cleaned Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "output_path = '../data/cleaned/spotify_cleaned.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ“ Cleaned data saved to: {output_path}\")\n",
    "print(f\"  â†’ File size: {pd.read_csv(output_path).memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 10. CLEANING SUMMARY\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š CLEANING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Original Dataset:\n",
    "  â€¢ Rows: {len(df_original):,}\n",
    "  â€¢ Columns: {len(df_original.columns)}\n",
    "\n",
    "Cleaned Dataset:\n",
    "  â€¢ Rows: {len(df):,} ({len(df_original) - len(df)} removed)\n",
    "  â€¢ Columns: {len(df.columns)} ({len(df.columns) - len(df_original.columns)} added)\n",
    "  â€¢ Missing Values: 0\n",
    "  â€¢ Duplicates: 0\n",
    "\n",
    "New Features Created: {len(df.columns) - len(df_original.columns)}\n",
    "  â†’ is_premium_willing\n",
    "  â†’ is_premium_user\n",
    "  â†’ is_podcast_listener\n",
    "  â†’ engagement_score\n",
    "  â†’ content_diversity\n",
    "  â†’ high_satisfaction\n",
    "  â†’ tenure_category\n",
    "\n",
    "âœ… Data is now ready for analysis!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Next: Run notebook 03_analysis_insights.ipynb\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c3d046-74db-41b2-9a5e-e87c4bb2cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 9: Saving Cleaned Data\n",
      "======================================================================\n",
      "âœ“ Cleaned data saved to: data/cleaned/spotify_cleaned.csv\n",
      "  â†’ File size: 0.66 MB\n",
      "\n",
      "======================================================================\n",
      "CLEANING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Original Dataset:\n",
      "  â€¢ Rows: 520\n",
      "  â€¢ Columns: 20\n",
      "\n",
      "Cleaned Dataset:\n",
      "  â€¢ Rows: 519 (1 removed)\n",
      "  â€¢ Columns: 27 (7 added)\n",
      "  â€¢ Missing Values: 0\n",
      "  â€¢ Duplicates: 0\n",
      "\n",
      "New Features Created: 7\n",
      "  â†’ is_premium_willing\n",
      "  â†’ is_premium_user\n",
      "  â†’ is_podcast_listener\n",
      "  â†’ engagement_score\n",
      "  â†’ content_diversity\n",
      "  â†’ high_satisfaction\n",
      "  â†’ tenure_category\n",
      "\n",
      "âœ… Data is now ready for analysis!\n",
      "\n",
      "======================================================================\n",
      "Next: Run notebook 03_analysis_insights.ipynb\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 9. SAVE CLEANED DATA\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 9: Saving Cleaned Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "output_path = 'data/cleaned/spotify_cleaned.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ“ Cleaned data saved to: {output_path}\")\n",
    "print(f\"  â†’ File size: {pd.read_csv(output_path).memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 10. CLEANING SUMMARY\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Original Dataset:\n",
    "  â€¢ Rows: {len(df_original):,}\n",
    "  â€¢ Columns: {len(df_original.columns)}\n",
    "\n",
    "Cleaned Dataset:\n",
    "  â€¢ Rows: {len(df):,} ({len(df_original) - len(df)} removed)\n",
    "  â€¢ Columns: {len(df.columns)} ({len(df.columns) - len(df_original.columns)} added)\n",
    "  â€¢ Missing Values: 0\n",
    "  â€¢ Duplicates: 0\n",
    "\n",
    "New Features Created: {len(df.columns) - len(df_original.columns)}\n",
    "  â†’ is_premium_willing\n",
    "  â†’ is_premium_user\n",
    "  â†’ is_podcast_listener\n",
    "  â†’ engagement_score\n",
    "  â†’ content_diversity\n",
    "  â†’ high_satisfaction\n",
    "  â†’ tenure_category\n",
    "\n",
    "âœ… Data is now ready for analysis!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Next: Run notebook 03_analysis_insights.ipynb\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1000291-11c9-4e7e-97a4-1a2e1d9f8d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
