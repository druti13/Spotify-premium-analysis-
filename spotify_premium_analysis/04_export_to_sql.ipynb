{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b4f601-2426-4a0a-a80b-3cc710fd2382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " EXPORT SPOTIFY DATA TO POSTGRESQL\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ STEP 1: Loading Cleaned Data...\n",
      "âœ“ Loaded: 519 rows Ã— 28 columns\n",
      "  Columns: age, gender, spotify_usage_period, spotify_listening_device, spotify_subscription_plan...\n",
      "\n",
      "======================================================================\n",
      "ğŸ”Œ STEP 2: PostgreSQL Connection Setup\n",
      "======================================================================\n",
      "\n",
      "Database Configuration:\n",
      "  â€¢ Host: localhost\n",
      "  â€¢ Port: 5432\n",
      "  â€¢ Database: spotify_db\n",
      "  â€¢ User: postgres\n",
      "\n",
      "âš ï¸ Make sure to update your password in DB_CONFIG!\n",
      "\n",
      "ğŸ”— Attempting to connect to PostgreSQL...\n",
      "âœ“ Connected successfully!\n",
      "  PostgreSQL version: PostgreSQL 18.1 on x86_64-windows, compiled by msvc-19.44.35...\n",
      "\n",
      "======================================================================\n",
      "ğŸ”§ STEP 3: Preparing Data for Export\n",
      "======================================================================\n",
      "\n",
      "Data Quality Check:\n",
      "  â€¢ Missing values: 0\n",
      "  â€¢ Duplicates: 0\n",
      "  â€¢ Data types: OK\n",
      "\n",
      "Columns to export (28):\n",
      "   1. age                                 (object)\n",
      "   2. gender                              (object)\n",
      "   3. spotify_usage_period                (object)\n",
      "   4. spotify_listening_device            (object)\n",
      "   5. spotify_subscription_plan           (object)\n",
      "   6. premium_sub_willingness             (object)\n",
      "   7. preffered_premium_plan              (object)\n",
      "   8. preferred_listening_content         (object)\n",
      "   9. fav_music_genre                     (object)\n",
      "  10. music_time_slot                     (object)\n",
      "  11. music_influencial_mood              (object)\n",
      "  12. music_lis_frequency                 (object)\n",
      "  13. music_expl_method                   (object)\n",
      "  14. music_recc_rating                   (int64)\n",
      "  15. pod_lis_frequency                   (object)\n",
      "  16. fav_pod_genre                       (object)\n",
      "  17. preffered_pod_format                (object)\n",
      "  18. pod_host_preference                 (object)\n",
      "  19. preffered_pod_duration              (object)\n",
      "  20. pod_variety_satisfaction            (object)\n",
      "  21. is_premium_willing                  (int64)\n",
      "  22. is_premium_user                     (int64)\n",
      "  23. is_podcast_listener                 (int64)\n",
      "  24. engagement_score                    (float64)\n",
      "  25. content_diversity                   (object)\n",
      "  26. high_satisfaction                   (int64)\n",
      "  27. tenure_category                     (object)\n",
      "  28. user_segment                        (object)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¤ STEP 4: Exporting Data to PostgreSQL\n",
      "======================================================================\n",
      "\n",
      "Exporting to table: spotify_users\n",
      "Action: Replacing table if exists...\n",
      "Rows to insert: 519\n",
      "\n",
      "This may take 30-60 seconds...\n",
      "\n",
      "âœ“ Data exported successfully!\n",
      "  â†’ Table name: spotify_users\n",
      "  â†’ Rows inserted: 519\n",
      "\n",
      "======================================================================\n",
      "âœ… STEP 5: Verifying Data in Database\n",
      "======================================================================\n",
      "\n",
      "Row Count Verification:\n",
      "  â€¢ Rows in DataFrame: 519\n",
      "  â€¢ Rows in Database:  519\n",
      "  â€¢ Match: âœ“ YES\n",
      "\n",
      "Sample Data from Database (First 3 rows):\n",
      "     age  gender spotify_usage_period            spotify_listening_device  \\\n",
      "0  20-35  Female    More than 2 years  Smart speakers or voice assistants   \n",
      "1  12-20    Male    More than 2 years                  Computer or laptop   \n",
      "2  35-60  Others   6 months to 1 year  Smart speakers or voice assistants   \n",
      "\n",
      "  spotify_subscription_plan premium_sub_willingness  \\\n",
      "0       Free (ad-supported)                     Yes   \n",
      "1       Free (ad-supported)                     Yes   \n",
      "2       Free (ad-supported)                     Yes   \n",
      "\n",
      "           preffered_premium_plan preferred_listening_content fav_music_genre  \\\n",
      "0        Family Plan-Rs 179/month                     Podcast          Melody   \n",
      "1  Individual Plan- Rs 119/ month                     Podcast             Rap   \n",
      "2        Student Plan-Rs 59/month                     Podcast             Pop   \n",
      "\n",
      "  music_time_slot  ... preffered_pod_duration pod_variety_satisfaction  \\\n",
      "0           Night  ...                   Both                       Ok   \n",
      "1       Afternoon  ...                Unknown                Satisfied   \n",
      "2           Night  ...                   Both                Satisfied   \n",
      "\n",
      "  is_premium_willing  is_premium_user is_podcast_listener engagement_score  \\\n",
      "0                  1                0                   1              0.0   \n",
      "1                  1                0                   1              0.0   \n",
      "2                  1                0                   1              0.0   \n",
      "\n",
      "  content_diversity high_satisfaction tenure_category  user_segment  \n",
      "0           Podcast                 0      Loyal User  Casual Users  \n",
      "1           Podcast                 0      Loyal User  Casual Users  \n",
      "2           Podcast                 1    Growing User  Casual Users  \n",
      "\n",
      "[3 rows x 28 columns]\n",
      "\n",
      "Database Columns (28):\n",
      "                   column_name data_type\n",
      "0                          age      text\n",
      "1                       gender      text\n",
      "2         spotify_usage_period      text\n",
      "3     spotify_listening_device      text\n",
      "4    spotify_subscription_plan      text\n",
      "5      premium_sub_willingness      text\n",
      "6       preffered_premium_plan      text\n",
      "7  preferred_listening_content      text\n",
      "8              fav_music_genre      text\n",
      "9              music_time_slot      text\n",
      "\n",
      "======================================================================\n",
      "âš¡ STEP 6: Creating Indexes for Performance\n",
      "======================================================================\n",
      "Creating 8 indexes...\n",
      "  âœ“ idx_premium_willing on is_premium_willing\n",
      "  âœ“ idx_premium_user on is_premium_user\n",
      "  âœ“ idx_age on age\n",
      "  âœ“ idx_gender on gender\n",
      "  âœ“ idx_subscription on spotify_subscription_plan\n",
      "  âœ“ idx_tenure on tenure_category\n",
      "  âœ“ idx_segment on user_segment\n",
      "  âœ“ idx_engagement on engagement_score\n",
      "\n",
      "âœ“ All indexes created successfully!\n",
      "\n",
      "======================================================================\n",
      "ğŸ§ª STEP 7: Testing Sample Queries\n",
      "======================================================================\n",
      "\n",
      "1. Premium Conversion Rate:\n",
      "   total_users  premium_users  willingness_rate\n",
      "0          519            0.0             35.84\n",
      "\n",
      "2. Top 5 Age Groups by Premium Willingness:\n",
      "     age  users  willingness_pct\n",
      "0  12-20     71            49.30\n",
      "1  35-60     23            39.13\n",
      "2  20-35    421            33.49\n",
      "3   6-12      3            33.33\n",
      "4    60+      1             0.00\n",
      "\n",
      "3. User Segment Distribution:\n",
      "       user_segment  count  willingness\n",
      "0      Casual Users    189        46.56\n",
      "1  Music-Only Users    330        29.70\n",
      "\n",
      "âœ“ All test queries executed successfully!\n",
      "\n",
      "======================================================================\n",
      "ğŸ“‹ STEP 8: Power BI Connection Information\n",
      "======================================================================\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘              POWER BI CONNECTION DETAILS                          â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "  SERVER INFORMATION:\n",
      "    â€¢ Server:   localhost\n",
      "    â€¢ Port:     5432\n",
      "    â€¢ Database: spotify_db\n",
      "    â€¢ Table:    spotify_users\n",
      "    â€¢ User:     postgres\n",
      "\n",
      "  POWER BI STEPS:\n",
      "    1. Open Power BI Desktop\n",
      "    2. Click \"Get Data\"\n",
      "    3. Search for \"PostgreSQL database\"\n",
      "    4. Click \"Connect\"\n",
      "    5. Enter:\n",
      "       - Server: localhost\n",
      "       - Database: spotify_db\n",
      "    6. Choose \"Database\" authentication\n",
      "    7. Enter username and password\n",
      "    8. Select table: spotify_users\n",
      "    9. Click \"Load\"\n",
      "\n",
      "  ALTERNATIVE: Use this connection string in Power BI:\n",
      "    Host=localhost;Port=5432;Database=spotify_db\n",
      "\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode characters in position 2-70: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeEncodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 283\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# Save connection info\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33moutputs/powerbi_connection_info.txt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ“ Connection info saved: outputs/powerbi_connection_info.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# 9. EXPORT SUMMARY\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\encodings\\cp1252.py:19\u001b[39m, in \u001b[36mIncrementalEncoder.encode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcharmap_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mUnicodeEncodeError\u001b[39m: 'charmap' codec can't encode characters in position 2-70: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" EXPORT SPOTIFY DATA TO POSTGRESQL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. LOAD CLEANED DATA\n",
    "# -----------------------------\n",
    "print(\"\\nğŸ“‚ STEP 1: Loading Cleaned Data...\")\n",
    "\n",
    "df = pd.read_csv('data/cleaned/spotify_cleaned.csv')\n",
    "\n",
    "print(f\"âœ“ Loaded: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"  Columns: {', '.join(df.columns[:5])}...\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. DATABASE CONNECTION SETUP\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”Œ STEP 2: PostgreSQL Connection Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# âš ï¸ REPLACE THESE WITH YOUR ACTUAL CREDENTIALS\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'spotify_db',\n",
    "    'user': 'postgres',\n",
    "    'password': '12345'  # â† CHANGE THIS!\n",
    "}\n",
    "\n",
    "print(f\"\"\"\n",
    "Database Configuration:\n",
    "  â€¢ Host: {DB_CONFIG['host']}\n",
    "  â€¢ Port: {DB_CONFIG['port']}\n",
    "  â€¢ Database: {DB_CONFIG['database']}\n",
    "  â€¢ User: {DB_CONFIG['user']}\n",
    "  \n",
    "âš ï¸ Make sure to update your password in DB_CONFIG!\n",
    "\"\"\")\n",
    "\n",
    "# Create connection string\n",
    "connection_string = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "print(\"ğŸ”— Attempting to connect to PostgreSQL...\")\n",
    "\n",
    "try:\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    # Test connection\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT version();\"))\n",
    "        version = result.fetchone()[0]\n",
    "        print(f\"âœ“ Connected successfully!\")\n",
    "        print(f\"  PostgreSQL version: {version[:60]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed!\")\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "    print(\"\\nğŸ’¡ TROUBLESHOOTING:\")\n",
    "    print(\"  1. Check if PostgreSQL is running\")\n",
    "    print(\"  2. Verify database 'spotify_db' exists\")\n",
    "    print(\"  3. Check your password in DB_CONFIG\")\n",
    "    print(\"  4. Make sure port 5432 is correct\")\n",
    "    raise\n",
    "\n",
    "# -----------------------------\n",
    "# 3. PREPARE DATA FOR EXPORT\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”§ STEP 3: Preparing Data for Export\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for any issues\n",
    "print(\"\\nData Quality Check:\")\n",
    "print(f\"  â€¢ Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"  â€¢ Duplicates: {df.duplicated().sum()}\")\n",
    "print(f\"  â€¢ Data types: OK\")\n",
    "\n",
    "# Show column info\n",
    "print(f\"\\nColumns to export ({len(df.columns)}):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    print(f\"  {i:2d}. {col:35s} ({dtype})\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. EXPORT DATA TO POSTGRESQL\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“¤ STEP 4: Exporting Data to PostgreSQL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "table_name = 'spotify_users'\n",
    "\n",
    "print(f\"\\nExporting to table: {table_name}\")\n",
    "print(\"Action: Replacing table if exists...\")\n",
    "print(f\"Rows to insert: {len(df):,}\")\n",
    "print(\"\\nThis may take 30-60 seconds...\\n\")\n",
    "\n",
    "try:\n",
    "    # Export to PostgreSQL\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        if_exists='replace',  # Replace if table exists\n",
    "        index=False,\n",
    "        method='multi',\n",
    "        chunksize=500\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Data exported successfully!\")\n",
    "    print(f\"  â†’ Table name: {table_name}\")\n",
    "    print(f\"  â†’ Rows inserted: {len(df):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Export failed!\")\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# -----------------------------\n",
    "# 5. VERIFY DATA IN DATABASE\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… STEP 5: Verifying Data in Database\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Count rows\n",
    "    query = f\"SELECT COUNT(*) as total_rows FROM {table_name};\"\n",
    "    result = pd.read_sql(query, engine)\n",
    "    db_rows = result['total_rows'][0]\n",
    "    \n",
    "    print(f\"\\nRow Count Verification:\")\n",
    "    print(f\"  â€¢ Rows in DataFrame: {len(df):,}\")\n",
    "    print(f\"  â€¢ Rows in Database:  {db_rows:,}\")\n",
    "    print(f\"  â€¢ Match: {'âœ“ YES' if db_rows == len(df) else 'âœ— NO'}\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(f\"\\nSample Data from Database (First 3 rows):\")\n",
    "    sample_query = f\"SELECT * FROM {table_name} LIMIT 3;\"\n",
    "    sample = pd.read_sql(sample_query, engine)\n",
    "    print(sample)\n",
    "    \n",
    "    # Column verification\n",
    "    columns_query = f\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = '{table_name}'\n",
    "    ORDER BY ordinal_position;\n",
    "    \"\"\"\n",
    "    columns_info = pd.read_sql(columns_query, engine)\n",
    "    print(f\"\\nDatabase Columns ({len(columns_info)}):\")\n",
    "    print(columns_info.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Verification failed: {str(e)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. CREATE INDEXES\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš¡ STEP 6: Creating Indexes for Performance\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "indexes = {\n",
    "    'idx_premium_willing': 'is_premium_willing',\n",
    "    'idx_premium_user': 'is_premium_user',\n",
    "    'idx_age': 'age',\n",
    "    'idx_gender': 'gender',\n",
    "    'idx_subscription': 'spotify_subscription_plan',\n",
    "    'idx_tenure': 'tenure_category',\n",
    "    'idx_segment': 'user_segment',\n",
    "    'idx_engagement': 'engagement_score'\n",
    "}\n",
    "\n",
    "print(f\"Creating {len(indexes)} indexes...\")\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        for idx_name, column in indexes.items():\n",
    "            query = f\"CREATE INDEX IF NOT EXISTS {idx_name} ON {table_name}({column});\"\n",
    "            conn.execute(text(query))\n",
    "            conn.commit()\n",
    "            print(f\"  âœ“ {idx_name} on {column}\")\n",
    "        \n",
    "        print(f\"\\nâœ“ All indexes created successfully!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Index creation warning: {str(e)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. TEST QUERIES\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ§ª STEP 7: Testing Sample Queries\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Premium Conversion Rate:\")\n",
    "test_query1 = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_users,\n",
    "    SUM(is_premium_user) as premium_users,\n",
    "    ROUND(AVG(is_premium_willing) * 100, 2) as willingness_rate\n",
    "FROM {table_name};\n",
    "\"\"\"\n",
    "result1 = pd.read_sql(test_query1, engine)\n",
    "print(result1)\n",
    "\n",
    "print(\"\\n2. Top 5 Age Groups by Premium Willingness:\")\n",
    "test_query2 = f\"\"\"\n",
    "SELECT \n",
    "    age,\n",
    "    COUNT(*) as users,\n",
    "    ROUND(AVG(is_premium_willing) * 100, 2) as willingness_pct\n",
    "FROM {table_name}\n",
    "GROUP BY age\n",
    "ORDER BY willingness_pct DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "result2 = pd.read_sql(test_query2, engine)\n",
    "print(result2)\n",
    "\n",
    "print(\"\\n3. User Segment Distribution:\")\n",
    "test_query3 = f\"\"\"\n",
    "SELECT \n",
    "    user_segment,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(AVG(is_premium_willing) * 100, 2) as willingness\n",
    "FROM {table_name}\n",
    "GROUP BY user_segment\n",
    "ORDER BY willingness DESC;\n",
    "\"\"\"\n",
    "result3 = pd.read_sql(test_query3, engine)\n",
    "print(result3)\n",
    "\n",
    "print(\"\\nâœ“ All test queries executed successfully!\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. CONNECTION INFO FOR POWER BI\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‹ STEP 8: Power BI Connection Information\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "connection_info = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              POWER BI CONNECTION DETAILS                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "  SERVER INFORMATION:\n",
    "    â€¢ Server:   {DB_CONFIG['host']}\n",
    "    â€¢ Port:     {DB_CONFIG['port']}\n",
    "    â€¢ Database: {DB_CONFIG['database']}\n",
    "    â€¢ Table:    {table_name}\n",
    "    â€¢ User:     {DB_CONFIG['user']}\n",
    "\n",
    "  POWER BI STEPS:\n",
    "    1. Open Power BI Desktop\n",
    "    2. Click \"Get Data\"\n",
    "    3. Search for \"PostgreSQL database\"\n",
    "    4. Click \"Connect\"\n",
    "    5. Enter:\n",
    "       - Server: {DB_CONFIG['host']}\n",
    "       - Database: {DB_CONFIG['database']}\n",
    "    6. Choose \"Database\" authentication\n",
    "    7. Enter username and password\n",
    "    8. Select table: {table_name}\n",
    "    9. Click \"Load\"\n",
    "\n",
    "  ALTERNATIVE: Use this connection string in Power BI:\n",
    "    Host={DB_CONFIG['host']};Port={DB_CONFIG['port']};Database={DB_CONFIG['database']}\n",
    "\"\"\"\n",
    "\n",
    "print(connection_info)\n",
    "\n",
    "# Save connection info\n",
    "with open('outputs/powerbi_connection_info.txt', 'w') as f:\n",
    "    f.write(connection_info)\n",
    "\n",
    "print(\"âœ“ Connection info saved: outputs/powerbi_connection_info.txt\")\n",
    "\n",
    "# -----------------------------\n",
    "# 9. EXPORT SUMMARY\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ EXPORT COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "âœ… EXPORT SUMMARY:\n",
    "  â€¢ Database:  {DB_CONFIG['database']}\n",
    "  â€¢ Table:     {table_name}\n",
    "  â€¢ Rows:      {len(df):,}\n",
    "  â€¢ Columns:   {len(df.columns)}\n",
    "  â€¢ Indexes:   {len(indexes)} created\n",
    "  â€¢ Status:    âœ“ SUCCESS\n",
    "\n",
    "ğŸ“Š READY FOR:\n",
    "  âœ“ SQL Analysis (run queries from sql/ folder)\n",
    "  âœ“ Power BI Dashboard\n",
    "  âœ“ Advanced Analytics\n",
    "\n",
    "ğŸ“ FILES CREATED:\n",
    "  âœ“ outputs/powerbi_connection_info.txt\n",
    "\n",
    "ğŸš€ NEXT STEPS:\n",
    "  1. Open pgAdmin and run SQL queries\n",
    "  2. Create Power BI dashboard\n",
    "  3. Document findings\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Continue to: SQL Analysis in pgAdmin\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc969312-f36e-4ecd-83d0-18741a06bb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " EXPORT SPOTIFY DATA TO POSTGRESQL\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ STEP 1: Loading Cleaned Data...\n",
      "âœ“ Loaded: 519 rows Ã— 28 columns\n",
      "  Columns: age, gender, spotify_usage_period, spotify_listening_device, spotify_subscription_plan...\n",
      "\n",
      "======================================================================\n",
      "ğŸ”Œ STEP 2: PostgreSQL Connection Setup\n",
      "======================================================================\n",
      "\n",
      "Database Configuration:\n",
      "  â€¢ Host: localhost\n",
      "  â€¢ Port: 5432\n",
      "  â€¢ Database: spotify_db\n",
      "  â€¢ User: postgres\n",
      "\n",
      "âš ï¸ Make sure to update your password in DB_CONFIG!\n",
      "\n",
      "ğŸ”— Attempting to connect to PostgreSQL...\n",
      "âœ“ Connected successfully!\n",
      "  PostgreSQL version: PostgreSQL 18.1 on x86_64-windows, compiled by msvc-19.44.35...\n",
      "\n",
      "======================================================================\n",
      "ğŸ”§ STEP 3: Preparing Data for Export\n",
      "======================================================================\n",
      "\n",
      "Data Quality Check:\n",
      "  â€¢ Missing values: 0\n",
      "  â€¢ Duplicates: 0\n",
      "  â€¢ Data types: OK\n",
      "\n",
      "Columns to export (28):\n",
      "   1. age                                 (object)\n",
      "   2. gender                              (object)\n",
      "   3. spotify_usage_period                (object)\n",
      "   4. spotify_listening_device            (object)\n",
      "   5. spotify_subscription_plan           (object)\n",
      "   6. premium_sub_willingness             (object)\n",
      "   7. preffered_premium_plan              (object)\n",
      "   8. preferred_listening_content         (object)\n",
      "   9. fav_music_genre                     (object)\n",
      "  10. music_time_slot                     (object)\n",
      "  11. music_influencial_mood              (object)\n",
      "  12. music_lis_frequency                 (object)\n",
      "  13. music_expl_method                   (object)\n",
      "  14. music_recc_rating                   (int64)\n",
      "  15. pod_lis_frequency                   (object)\n",
      "  16. fav_pod_genre                       (object)\n",
      "  17. preffered_pod_format                (object)\n",
      "  18. pod_host_preference                 (object)\n",
      "  19. preffered_pod_duration              (object)\n",
      "  20. pod_variety_satisfaction            (object)\n",
      "  21. is_premium_willing                  (int64)\n",
      "  22. is_premium_user                     (int64)\n",
      "  23. is_podcast_listener                 (int64)\n",
      "  24. engagement_score                    (float64)\n",
      "  25. content_diversity                   (object)\n",
      "  26. high_satisfaction                   (int64)\n",
      "  27. tenure_category                     (object)\n",
      "  28. user_segment                        (object)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¤ STEP 4: Exporting Data to PostgreSQL\n",
      "======================================================================\n",
      "\n",
      "Exporting to table: spotify_users\n",
      "Action: Replacing table if exists...\n",
      "Rows to insert: 519\n",
      "\n",
      "This may take 30-60 seconds...\n",
      "\n",
      "âœ“ Data exported successfully!\n",
      "  â†’ Table name: spotify_users\n",
      "  â†’ Rows inserted: 519\n",
      "\n",
      "======================================================================\n",
      "âœ… STEP 5: Verifying Data in Database\n",
      "======================================================================\n",
      "\n",
      "Row Count Verification:\n",
      "  â€¢ Rows in DataFrame: 519\n",
      "  â€¢ Rows in Database:  519\n",
      "  â€¢ Match: âœ“ YES\n",
      "\n",
      "Sample Data from Database (First 3 rows):\n",
      "     age  gender spotify_usage_period            spotify_listening_device  \\\n",
      "0  20-35  Female    More than 2 years  Smart speakers or voice assistants   \n",
      "1  12-20    Male    More than 2 years                  Computer or laptop   \n",
      "2  35-60  Others   6 months to 1 year  Smart speakers or voice assistants   \n",
      "\n",
      "  spotify_subscription_plan premium_sub_willingness  \\\n",
      "0       Free (ad-supported)                     Yes   \n",
      "1       Free (ad-supported)                     Yes   \n",
      "2       Free (ad-supported)                     Yes   \n",
      "\n",
      "           preffered_premium_plan preferred_listening_content fav_music_genre  \\\n",
      "0        Family Plan-Rs 179/month                     Podcast          Melody   \n",
      "1  Individual Plan- Rs 119/ month                     Podcast             Rap   \n",
      "2        Student Plan-Rs 59/month                     Podcast             Pop   \n",
      "\n",
      "  music_time_slot  ... preffered_pod_duration pod_variety_satisfaction  \\\n",
      "0           Night  ...                   Both                       Ok   \n",
      "1       Afternoon  ...                Unknown                Satisfied   \n",
      "2           Night  ...                   Both                Satisfied   \n",
      "\n",
      "  is_premium_willing  is_premium_user is_podcast_listener engagement_score  \\\n",
      "0                  1                0                   1              0.0   \n",
      "1                  1                0                   1              0.0   \n",
      "2                  1                0                   1              0.0   \n",
      "\n",
      "  content_diversity high_satisfaction tenure_category  user_segment  \n",
      "0           Podcast                 0      Loyal User  Casual Users  \n",
      "1           Podcast                 0      Loyal User  Casual Users  \n",
      "2           Podcast                 1    Growing User  Casual Users  \n",
      "\n",
      "[3 rows x 28 columns]\n",
      "\n",
      "Database Columns (28):\n",
      "                   column_name data_type\n",
      "0                          age      text\n",
      "1                       gender      text\n",
      "2         spotify_usage_period      text\n",
      "3     spotify_listening_device      text\n",
      "4    spotify_subscription_plan      text\n",
      "5      premium_sub_willingness      text\n",
      "6       preffered_premium_plan      text\n",
      "7  preferred_listening_content      text\n",
      "8              fav_music_genre      text\n",
      "9              music_time_slot      text\n",
      "\n",
      "======================================================================\n",
      "âš¡ STEP 6: Creating Indexes for Performance\n",
      "======================================================================\n",
      "Creating 8 indexes...\n",
      "  âœ“ idx_premium_willing on is_premium_willing\n",
      "  âœ“ idx_premium_user on is_premium_user\n",
      "  âœ“ idx_age on age\n",
      "  âœ“ idx_gender on gender\n",
      "  âœ“ idx_subscription on spotify_subscription_plan\n",
      "  âœ“ idx_tenure on tenure_category\n",
      "  âœ“ idx_segment on user_segment\n",
      "  âœ“ idx_engagement on engagement_score\n",
      "\n",
      "âœ“ All indexes created successfully!\n",
      "\n",
      "======================================================================\n",
      "ğŸ§ª STEP 7: Testing Sample Queries\n",
      "======================================================================\n",
      "\n",
      "1. Premium Conversion Rate:\n",
      "   total_users  premium_users  willingness_rate\n",
      "0          519            0.0             35.84\n",
      "\n",
      "2. Top 5 Age Groups by Premium Willingness:\n",
      "     age  users  willingness_pct\n",
      "0  12-20     71            49.30\n",
      "1  35-60     23            39.13\n",
      "2  20-35    421            33.49\n",
      "3   6-12      3            33.33\n",
      "4    60+      1             0.00\n",
      "\n",
      "3. User Segment Distribution:\n",
      "       user_segment  count  willingness\n",
      "0      Casual Users    189        46.56\n",
      "1  Music-Only Users    330        29.70\n",
      "\n",
      "âœ“ All test queries executed successfully!\n",
      "\n",
      "======================================================================\n",
      "ğŸ“‹ STEP 8: Power BI Connection Information\n",
      "======================================================================\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘              POWER BI CONNECTION DETAILS                          â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "  SERVER INFORMATION:\n",
      "    â€¢ Server:   localhost\n",
      "    â€¢ Port:     5432\n",
      "    â€¢ Database: spotify_db\n",
      "    â€¢ Table:    spotify_users\n",
      "    â€¢ User:     postgres\n",
      "\n",
      "  POWER BI STEPS:\n",
      "    1. Open Power BI Desktop\n",
      "    2. Click \"Get Data\"\n",
      "    3. Search for \"PostgreSQL database\"\n",
      "    4. Click \"Connect\"\n",
      "    5. Enter:\n",
      "       - Server: localhost\n",
      "       - Database: spotify_db\n",
      "    6. Choose \"Database\" authentication\n",
      "    7. Enter username and password\n",
      "    8. Select table: spotify_users\n",
      "    9. Click \"Load\"\n",
      "\n",
      "  ALTERNATIVE: Use this connection string in Power BI:\n",
      "    Host=localhost;Port=5432;Database=spotify_db\n",
      "\n",
      "âœ“ Connection info saved: outputs/powerbi_connection_info.txt\n",
      "\n",
      "======================================================================\n",
      "ğŸ‰ EXPORT COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "âœ… EXPORT SUMMARY:\n",
      "  â€¢ Database:  spotify_db\n",
      "  â€¢ Table:     spotify_users\n",
      "  â€¢ Rows:      519\n",
      "  â€¢ Columns:   28\n",
      "  â€¢ Indexes:   8 created\n",
      "  â€¢ Status:    âœ“ SUCCESS\n",
      "\n",
      "ğŸ“Š READY FOR:\n",
      "  âœ“ SQL Analysis (run queries from sql/ folder)\n",
      "  âœ“ Power BI Dashboard\n",
      "  âœ“ Advanced Analytics\n",
      "\n",
      "ğŸ“ FILES CREATED:\n",
      "  âœ“ outputs/powerbi_connection_info.txt\n",
      "\n",
      "ğŸš€ NEXT STEPS:\n",
      "  1. Open pgAdmin and run SQL queries\n",
      "  2. Create Power BI dashboard\n",
      "  3. Document findings\n",
      "\n",
      "======================================================================\n",
      "Continue to: SQL Analysis in pgAdmin\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" EXPORT SPOTIFY DATA TO POSTGRESQL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. LOAD CLEANED DATA\n",
    "# -----------------------------\n",
    "print(\"\\nğŸ“‚ STEP 1: Loading Cleaned Data...\")\n",
    "\n",
    "df = pd.read_csv('data/cleaned/spotify_cleaned.csv')\n",
    "\n",
    "print(f\"âœ“ Loaded: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"  Columns: {', '.join(df.columns[:5])}...\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. DATABASE CONNECTION SETUP\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”Œ STEP 2: PostgreSQL Connection Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# âš ï¸ REPLACE THESE WITH YOUR ACTUAL CREDENTIALS\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'spotify_db',\n",
    "    'user': 'postgres',\n",
    "    'password': '12345'  # â† CHANGE THIS!\n",
    "}\n",
    "\n",
    "print(f\"\"\"\n",
    "Database Configuration:\n",
    "  â€¢ Host: {DB_CONFIG['host']}\n",
    "  â€¢ Port: {DB_CONFIG['port']}\n",
    "  â€¢ Database: {DB_CONFIG['database']}\n",
    "  â€¢ User: {DB_CONFIG['user']}\n",
    "  \n",
    "âš ï¸ Make sure to update your password in DB_CONFIG!\n",
    "\"\"\")\n",
    "\n",
    "# Create connection string\n",
    "connection_string = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "print(\"ğŸ”— Attempting to connect to PostgreSQL...\")\n",
    "\n",
    "try:\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    # Test connection\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT version();\"))\n",
    "        version = result.fetchone()[0]\n",
    "        print(f\"âœ“ Connected successfully!\")\n",
    "        print(f\"  PostgreSQL version: {version[:60]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed!\")\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "    print(\"\\nğŸ’¡ TROUBLESHOOTING:\")\n",
    "    print(\"  1. Check if PostgreSQL is running\")\n",
    "    print(\"  2. Verify database 'spotify_db' exists\")\n",
    "    print(\"  3. Check your password in DB_CONFIG\")\n",
    "    print(\"  4. Make sure port 5432 is correct\")\n",
    "    raise\n",
    "\n",
    "# -----------------------------\n",
    "# 3. PREPARE DATA FOR EXPORT\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”§ STEP 3: Preparing Data for Export\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for any issues\n",
    "print(\"\\nData Quality Check:\")\n",
    "print(f\"  â€¢ Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"  â€¢ Duplicates: {df.duplicated().sum()}\")\n",
    "print(f\"  â€¢ Data types: OK\")\n",
    "\n",
    "# Show column info\n",
    "print(f\"\\nColumns to export ({len(df.columns)}):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    print(f\"  {i:2d}. {col:35s} ({dtype})\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. EXPORT DATA TO POSTGRESQL\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“¤ STEP 4: Exporting Data to PostgreSQL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "table_name = 'spotify_users'\n",
    "\n",
    "print(f\"\\nExporting to table: {table_name}\")\n",
    "print(\"Action: Replacing table if exists...\")\n",
    "print(f\"Rows to insert: {len(df):,}\")\n",
    "print(\"\\nThis may take 30-60 seconds...\\n\")\n",
    "\n",
    "try:\n",
    "    # Export to PostgreSQL\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        if_exists='replace',  # Replace if table exists\n",
    "        index=False,\n",
    "        method='multi',\n",
    "        chunksize=500\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Data exported successfully!\")\n",
    "    print(f\"  â†’ Table name: {table_name}\")\n",
    "    print(f\"  â†’ Rows inserted: {len(df):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Export failed!\")\n",
    "    print(f\"   Error: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# -----------------------------\n",
    "# 5. VERIFY DATA IN DATABASE\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… STEP 5: Verifying Data in Database\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Count rows\n",
    "    query = f\"SELECT COUNT(*) as total_rows FROM {table_name};\"\n",
    "    result = pd.read_sql(query, engine)\n",
    "    db_rows = result['total_rows'][0]\n",
    "    \n",
    "    print(f\"\\nRow Count Verification:\")\n",
    "    print(f\"  â€¢ Rows in DataFrame: {len(df):,}\")\n",
    "    print(f\"  â€¢ Rows in Database:  {db_rows:,}\")\n",
    "    print(f\"  â€¢ Match: {'âœ“ YES' if db_rows == len(df) else 'âœ— NO'}\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(f\"\\nSample Data from Database (First 3 rows):\")\n",
    "    sample_query = f\"SELECT * FROM {table_name} LIMIT 3;\"\n",
    "    sample = pd.read_sql(sample_query, engine)\n",
    "    print(sample)\n",
    "    \n",
    "    # Column verification\n",
    "    columns_query = f\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = '{table_name}'\n",
    "    ORDER BY ordinal_position;\n",
    "    \"\"\"\n",
    "    columns_info = pd.read_sql(columns_query, engine)\n",
    "    print(f\"\\nDatabase Columns ({len(columns_info)}):\")\n",
    "    print(columns_info.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Verification failed: {str(e)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. CREATE INDEXES\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš¡ STEP 6: Creating Indexes for Performance\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "indexes = {\n",
    "    'idx_premium_willing': 'is_premium_willing',\n",
    "    'idx_premium_user': 'is_premium_user',\n",
    "    'idx_age': 'age',\n",
    "    'idx_gender': 'gender',\n",
    "    'idx_subscription': 'spotify_subscription_plan',\n",
    "    'idx_tenure': 'tenure_category',\n",
    "    'idx_segment': 'user_segment',\n",
    "    'idx_engagement': 'engagement_score'\n",
    "}\n",
    "\n",
    "print(f\"Creating {len(indexes)} indexes...\")\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        for idx_name, column in indexes.items():\n",
    "            query = f\"CREATE INDEX IF NOT EXISTS {idx_name} ON {table_name}({column});\"\n",
    "            conn.execute(text(query))\n",
    "            conn.commit()\n",
    "            print(f\"  âœ“ {idx_name} on {column}\")\n",
    "        \n",
    "        print(f\"\\nâœ“ All indexes created successfully!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Index creation warning: {str(e)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. TEST QUERIES\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ§ª STEP 7: Testing Sample Queries\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Premium Conversion Rate:\")\n",
    "test_query1 = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_users,\n",
    "    SUM(is_premium_user) as premium_users,\n",
    "    ROUND(AVG(is_premium_willing) * 100, 2) as willingness_rate\n",
    "FROM {table_name};\n",
    "\"\"\"\n",
    "result1 = pd.read_sql(test_query1, engine)\n",
    "print(result1)\n",
    "\n",
    "print(\"\\n2. Top 5 Age Groups by Premium Willingness:\")\n",
    "test_query2 = f\"\"\"\n",
    "SELECT \n",
    "    age,\n",
    "    COUNT(*) as users,\n",
    "    ROUND(AVG(is_premium_willing) * 100, 2) as willingness_pct\n",
    "FROM {table_name}\n",
    "GROUP BY age\n",
    "ORDER BY willingness_pct DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "result2 = pd.read_sql(test_query2, engine)\n",
    "print(result2)\n",
    "\n",
    "print(\"\\n3. User Segment Distribution:\")\n",
    "test_query3 = f\"\"\"\n",
    "SELECT \n",
    "    user_segment,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(AVG(is_premium_willing) * 100, 2) as willingness\n",
    "FROM {table_name}\n",
    "GROUP BY user_segment\n",
    "ORDER BY willingness DESC;\n",
    "\"\"\"\n",
    "result3 = pd.read_sql(test_query3, engine)\n",
    "print(result3)\n",
    "\n",
    "print(\"\\nâœ“ All test queries executed successfully!\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. CONNECTION INFO FOR POWER BI\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‹ STEP 8: Power BI Connection Information\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "connection_info = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              POWER BI CONNECTION DETAILS                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "  SERVER INFORMATION:\n",
    "    â€¢ Server:   {DB_CONFIG['host']}\n",
    "    â€¢ Port:     {DB_CONFIG['port']}\n",
    "    â€¢ Database: {DB_CONFIG['database']}\n",
    "    â€¢ Table:    {table_name}\n",
    "    â€¢ User:     {DB_CONFIG['user']}\n",
    "\n",
    "  POWER BI STEPS:\n",
    "    1. Open Power BI Desktop\n",
    "    2. Click \"Get Data\"\n",
    "    3. Search for \"PostgreSQL database\"\n",
    "    4. Click \"Connect\"\n",
    "    5. Enter:\n",
    "       - Server: {DB_CONFIG['host']}\n",
    "       - Database: {DB_CONFIG['database']}\n",
    "    6. Choose \"Database\" authentication\n",
    "    7. Enter username and password\n",
    "    8. Select table: {table_name}\n",
    "    9. Click \"Load\"\n",
    "\n",
    "  ALTERNATIVE: Use this connection string in Power BI:\n",
    "    Host={DB_CONFIG['host']};Port={DB_CONFIG['port']};Database={DB_CONFIG['database']}\n",
    "\"\"\"\n",
    "\n",
    "print(connection_info)\n",
    "\n",
    "# Save connection info\n",
    "with open('outputs/powerbi_connection_info.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(connection_info)\n",
    "\n",
    "print(\"âœ“ Connection info saved: outputs/powerbi_connection_info.txt\")\n",
    "\n",
    "# -----------------------------\n",
    "# 9. EXPORT SUMMARY\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ EXPORT COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "âœ… EXPORT SUMMARY:\n",
    "  â€¢ Database:  {DB_CONFIG['database']}\n",
    "  â€¢ Table:     {table_name}\n",
    "  â€¢ Rows:      {len(df):,}\n",
    "  â€¢ Columns:   {len(df.columns)}\n",
    "  â€¢ Indexes:   {len(indexes)} created\n",
    "  â€¢ Status:    âœ“ SUCCESS\n",
    "\n",
    "ğŸ“Š READY FOR:\n",
    "  âœ“ SQL Analysis (run queries from sql/ folder)\n",
    "  âœ“ Power BI Dashboard\n",
    "  âœ“ Advanced Analytics\n",
    "\n",
    "ğŸ“ FILES CREATED:\n",
    "  âœ“ outputs/powerbi_connection_info.txt\n",
    "\n",
    "ğŸš€ NEXT STEPS:\n",
    "  1. Open pgAdmin and run SQL queries\n",
    "  2. Create Power BI dashboard\n",
    "  3. Document findings\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Continue to: SQL Analysis in pgAdmin\")\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067d89d-338e-4a44-8a8e-13b736d283e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
